{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKrJMy1OVtTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6392cb2-42df-486c-b23e-1306c6e6fc19"
      },
      "source": [
        "%matplotlib inline\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import collections\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "torch.set_printoptions(edgeitems=2)\r\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fda6ed2a240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4-AsOfkf-Es"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\r\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xQ_tusBf-Hb",
        "outputId": "00b980d6-61f7-4bec-8fa7-ce20ab264386"
      },
      "source": [
        "from torchvision import datasets, transforms\r\n",
        "data_path = '/content/drive/MyDrive'\r\n",
        "cifar10 = datasets.CIFAR10(\r\n",
        "    data_path, train=True, download=True,\r\n",
        "    transform=transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\r\n",
        "                  (0.2470, 0.2435, 0.2616))\r\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJvIBuGSf-KL",
        "outputId": "a6fd387a-f281-4027-c260-6adb6aa244cb"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\r\n",
        "    data_path, train=False, download=True,\r\n",
        "    transform=transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\r\n",
        "                             (0.2470, 0.2435, 0.2616))\r\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iELCF1b1f-NK"
      },
      "source": [
        "label_map = {0: 0, 2: 1}\r\n",
        "class_names = ['airplane', 'bird']\r\n",
        "cifar2 = [(img, label_map[label])\r\n",
        "          for img, label in cifar10\r\n",
        "          if label in [0, 2]]\r\n",
        "cifar2_val = [(img, label_map[label])\r\n",
        "              for img, label in cifar10_val\r\n",
        "              if label in [0, 2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac4w52ComViP",
        "outputId": "c169a769-07ff-456c-8b36-257ab9f06a39"
      },
      "source": [
        "\r\n",
        "conv = nn.Conv2d(3, 16, 3)\r\n",
        "\r\n",
        "conv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDlsDL1omdEo",
        "outputId": "2f497889-5b6d-4a8c-b259-1f808f51684a"
      },
      "source": [
        "#conv weight size: out_feature * input*feature * kernel_size, in our case: 16*3*3*3\r\n",
        "conv.weight.shape, conv.bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhHI0EOKnXGq",
        "outputId": "d4732083-5a3c-42bb-8cf0-b41a37878d35"
      },
      "source": [
        "# test the conv model, which expects input shape: B*C*H*W\r\n",
        "img, _ = cifar2[0]\r\n",
        "output = conv(img.unsqueeze(0))\r\n",
        "img.unsqueeze(0).shape, output.shape, type(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 30, 30]), torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "elzPpPBUn_Rr",
        "outputId": "c2566a91-3aaa-4989-a366-197eb4123656"
      },
      "source": [
        "plt.imshow(output[0, 0].detach(), cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l32-xrXXoJf0",
        "outputId": "5c51a8f4-8b2e-47e9-b8fe-cc1304b40ff8"
      },
      "source": [
        "# expecting to preserve the original size of pic, we will use padding\r\n",
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\r\n",
        "output = conv(img.unsqueeze(0))\r\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOq_-Z4_qCBJ"
      },
      "source": [
        "## 检查weight矩阵的作用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5heFP2sqFr4"
      },
      "source": [
        "# bias=0, weight=1/9, 所以每一个像素将会是周围9格的平均\r\n",
        "with torch.no_grad():\r\n",
        "  conv.bias.zero_()\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  conv.weight.fill_(1.0/9.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "4-EavOQAqPkd",
        "outputId": "da590052-6ba9-4fc3-eb83-4abd2aa8ce34"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\r\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLt32CYPqefd"
      },
      "source": [
        "#每个图片的右列减去左列\r\n",
        "conv = nn.Conv2d(3, 1, 3, 1)\r\n",
        "with torch.no_grad():\r\n",
        "  conv.weight[:] = torch.tensor([  [-1.0, 0.0, 1.0],\r\n",
        "                     [-1.0, 0.0, 1.0],\r\n",
        "                     [-1.0, 0.0, 1.0]\r\n",
        "                                 ])\r\n",
        "  conv.bias.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "5uidaM9prJtx",
        "outputId": "f821aa4f-9a3d-4f5e-f7c4-bbe5c5d49144"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\r\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trV5mamfr7oN"
      },
      "source": [
        "## from large picture to small: downsampling, maxpooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjuNQLJhrN-5",
        "outputId": "0190f71a-e196-4dbe-f35a-8e2d1388c36d"
      },
      "source": [
        "pool = nn.MaxPool2d(2)\r\n",
        "output = pool(img.unsqueeze(0))\r\n",
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8hzJ-67uYIS"
      },
      "source": [
        "## put it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHksqT7Jsrhi"
      },
      "source": [
        "model = nn.Sequential(\r\n",
        "    nn.Conv2d(3, 16, 3, 1),#input, output, kernelsize, padding\r\n",
        "    nn.Tanh(),\r\n",
        "    nn.MaxPool2d(2),\r\n",
        "    nn.Conv2d(16, 8, 3, 1),\r\n",
        "    nn.Tanh(),\r\n",
        "    nn.MaxPool2d(2),\r\n",
        "    # turn 8 channel 8*8 picture into 1D vector to produce prob\r\n",
        "    nn.Linear(8*8*8, 32),\r\n",
        "    nn.Tanh(),\r\n",
        "    nn.Linear(32, 2)\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX584VnHveeE",
        "outputId": "9b279e52-f62c-44a8-9aba-509db8ef49e0"
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\r\n",
        "sum(numel_list), numel_list "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "W0CljGQ6vrgv",
        "outputId": "ecd7b055-89c2-4a2e-a523-d061e7026225"
      },
      "source": [
        "model(img.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9c784fd7714c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (48x6 and 512x32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT7kW7Fs5DQi"
      },
      "source": [
        "# make our submodule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxEKf6cU4Y0g"
      },
      "source": [
        "# switch to functional API to avoid store non-parameter function in our model\r\n",
        "# that is why we abandon nn.Tanh(), nn.MaxPool2d and turn to torch.tanh(), F.maxpool()\r\n",
        "class Net(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size = 5, padding=2)\r\n",
        "    #self.act1 = nn.Tanh()\r\n",
        "    #self.pool1 = nn.MaxPool2d(2)\r\n",
        "    self.conv2 = nn.Conv2d(16, 8 ,kernel_size = 5, padding=2)\r\n",
        "    #self.act2 = nn.Tanh()\r\n",
        "    #self.pool2 = nn.MaxPool2d(2)\r\n",
        "    self.fc1 = nn.Linear(8*8*8, 32)\r\n",
        "    #self.act3 = nn.Tanh()\r\n",
        "    self.fc2 = nn.Linear(32, 2)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv1(x) ), 2)\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv2(out) ), 2 )\r\n",
        "    out = out.view(-1, 8*8*8) # most important line! to tackcle the former warning\r\n",
        "    out = torch.tanh( self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0lEmqbN6rHI"
      },
      "source": [
        "model = Net()\r\n",
        "numel_list = [p.numel() for p in model.parameters()]\r\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OMGTEwOCeh7"
      },
      "source": [
        "model = Net()\r\n",
        "model(img.unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL2zsn8SGjN8"
      },
      "source": [
        "## time to train our own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88hpfU7NF6Ic"
      },
      "source": [
        "import datetime\r\n",
        "\r\n",
        "def trainning_loop(n_epoches, optimizer, model, loss_fn, train_loader):\r\n",
        "  for epoch in range(1, 1+n_epoches):\r\n",
        "    loss_train =0.0\r\n",
        "    for imgs, labels in train_loader:\r\n",
        "      outputs = model(imgs)\r\n",
        "      loss = loss_fn(outputs, labels)\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "      loss_train += loss.item()  #use item() function to transfrom it to a Python number\r\n",
        "    if epoch==1 or epoch % 10==0:\r\n",
        "      print('{} Epoch {}, Trainning loss {}'.format(datetime.datetime.now(), epoch, loss_train/len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2SMdZTwHiuw"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle = True)\r\n",
        "model = Net()\r\n",
        "optimizer = optim.SGD(model.parameters(), 1e-2)\r\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YtHsFIwIILD"
      },
      "source": [
        "trainning_loop(100, optimizer, model, loss_fn, train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO8L4JhBIMfI"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def validate(model, train_loader, val_loader):\r\n",
        "  for name, loader in [('train', train_loader), ('val', val_loader)]:\r\n",
        "    correct, total = 0, 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      for imgs, labels in loader:\r\n",
        "        outputs = model(imgs)\r\n",
        "        _, predicted = torch.max(outputs, dim=1)\r\n",
        "        total += labels.shape[0]\r\n",
        "        correct += int( (labels == predicted).sum() )\r\n",
        "      \r\n",
        "    print('Accuracy {}: {:.2f} '.format(name, correct/total))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZRVK1yKv9E"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = False)\r\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 64, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWjT6FczJaH-"
      },
      "source": [
        "validate(model, train_loader, val_loader)\r\n",
        "# kernel size = 3, 0.93 on train, 0.88 on val\r\n",
        "# kernel size = 5, 0.97 on train, 0.88 on val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVj9uAQVhRb_"
      },
      "source": [
        "## store and load the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGi4IyaQKI6D"
      },
      "source": [
        "torch.save(model.state_dict(), data_path+'/birds_vs_airplanes.pt')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW66n4OzlnEN"
      },
      "source": [
        "loaded_model = Net()\r\n",
        "loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/birds_vs_airplanes.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N3A1pIvlKEv"
      },
      "source": [
        "# using GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJgdLzYpl9Mf",
        "outputId": "665dce1f-21d0-4832-cd5e-792fcb95142e"
      },
      "source": [
        "#checke whether the GPU is available\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "print(f\"training on device {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on device cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safNNwaDbhtz"
      },
      "source": [
        "# switch to functional API to avoid store non-parameter function in our model\r\n",
        "# that is why we abandon nn.Tanh(), nn.MaxPool2d and turn to torch.tanh(), F.maxpool()\r\n",
        "class Net(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size = 5, padding=2)\r\n",
        "    #self.act1 = nn.Tanh()\r\n",
        "    #self.pool1 = nn.MaxPool2d(2)\r\n",
        "    self.conv2 = nn.Conv2d(16, 8 ,kernel_size = 5, padding=2)\r\n",
        "    #self.act2 = nn.Tanh()\r\n",
        "    #self.pool2 = nn.MaxPool2d(2)\r\n",
        "    self.fc1 = nn.Linear(8*8*8, 32)\r\n",
        "    #self.act3 = nn.Tanh()\r\n",
        "    self.fc2 = nn.Linear(32, 2)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv1(x) ), 2)\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv2(out) ), 2 )\r\n",
        "    out = out.view(-1, 8*8*8) # most important line! to tackcle the former warning\r\n",
        "    out = torch.tanh( self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E4jU5RYi_TN"
      },
      "source": [
        "#we mainly use .to() function, the GPU can help us to increase training speed\r\n",
        "def training_loop_gpu(n_epoches, optimizer, loss_fn, train_loader):\r\n",
        "  for epoch in range(1, 1+ n_epoches):\r\n",
        "    loss_train = 0.0\r\n",
        "    for imgs, labels in train_loader:\r\n",
        "      imgs = imgs.to(device = device)\r\n",
        "      labels = labels.to(device = device) #these 2 lines are major different\r\n",
        "\r\n",
        "      outputs = model(imgs)\r\n",
        "      loss = loss_fn(outputs, labels)\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      loss_train += loss\r\n",
        "    if epoch==1 or epoch%10==0:\r\n",
        "      print('{} Epoch {}, Loss {}'.format(datetime.datetime.now(), epoch, loss_train/len(train_loader)))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rno7Te6ym60J"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = True)\r\n",
        "model = Net().to(device = device) # remember to transfer the Net to GPU as well!\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2) \r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omhW9519nN30",
        "outputId": "06f528ab-b4d4-4c2a-e09d-de9f88e12d42"
      },
      "source": [
        "import datetime\r\n",
        "training_loop_gpu(100, optimizer, loss_fn, train_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-10 14:57:49.310864 Epoch 1, Loss 0.47730693221092224\n",
            "2021-02-10 14:57:52.600787 Epoch 10, Loss 0.31472137570381165\n",
            "2021-02-10 14:57:56.293862 Epoch 20, Loss 0.275509774684906\n",
            "2021-02-10 14:57:59.980038 Epoch 30, Loss 0.24683944880962372\n",
            "2021-02-10 14:58:03.673513 Epoch 40, Loss 0.21980898082256317\n",
            "2021-02-10 14:58:07.288320 Epoch 50, Loss 0.19890835881233215\n",
            "2021-02-10 14:58:11.122820 Epoch 60, Loss 0.17566034197807312\n",
            "2021-02-10 14:58:14.878909 Epoch 70, Loss 0.15419557690620422\n",
            "2021-02-10 14:58:18.664368 Epoch 80, Loss 0.13913945853710175\n",
            "2021-02-10 14:58:22.329181 Epoch 90, Loss 0.12175217270851135\n",
            "2021-02-10 14:58:25.967274 Epoch 100, Loss 0.10535082221031189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjtj8vLdbw2Q"
      },
      "source": [
        "def validate_gpu(model, train_loader, val_loader):\r\n",
        "  for name, loader in [('train', train_loader), ('val', val_loader)]:\r\n",
        "    correct, total = 0, 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      for imgs, labels in loader:\r\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\r\n",
        "        outputs = model(imgs)\r\n",
        "        _, predicted = torch.max(outputs, dim=1)\r\n",
        "        total += labels.shape[0]\r\n",
        "        correct += int( (labels == predicted).sum() )\r\n",
        "      \r\n",
        "    print('Accuracy {}: {:.2f} '.format(name, correct/total))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP4CXi2hcLj-",
        "outputId": "30408a1b-10fa-4629-e60f-b9e776610d1f"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = False)\r\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 64, shuffle = False)\r\n",
        "validate_gpu(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.97 \n",
            "Accuracy val: 0.88 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5aPG50Cf_ec"
      },
      "source": [
        "# Chapter8-exe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yivNyFeHeLXa"
      },
      "source": [
        "import cv2\r\n",
        "image = cv2.imread('/content/drive/MyDrive/deep_learning_with_pytorch/rosket.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Om0cusIe1t6",
        "outputId": "33dedc8f-054f-4d39-a39a-6d612c1bdcef"
      },
      "source": [
        "image.shape, type(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((341, 500, 3), numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQdmKJJ2e1wq"
      },
      "source": [
        "img = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw3wuMGIe1zb",
        "outputId": "4d5fb8a7-8481-4e7a-bc1e-72bf6fae8d96"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PbKrSmse12J"
      },
      "source": [
        "img = torch.from_numpy(img).permute(2, 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDwzhjeJeLaL",
        "outputId": "cde1743e-f7f4-46ad-d368-5e7f8246ff7f"
      },
      "source": [
        "img.shape, type(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 32, 32]), torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x9ZnOY3fjEd"
      },
      "source": [
        "m = model.to(device)\r\n",
        "out = m(img.unsqueeze(0).float().to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTQe7jHgfjHs",
        "outputId": "658df8df-50a3-4fe3-ab00-d3ec9f71487d"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.3955,  3.8835]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgt1A16gfjLD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TsAgz77nVZa",
        "outputId": "de54fde0-db7b-4fff-dc70-a207e01f1e6b"
      },
      "source": [
        "# when store data, pytorch will store where the data derive, so we need to override the device info when loading\r\n",
        "loaded_model = Net().to(device=device)\r\n",
        "\r\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/birds_vs_airplanes.pt\", map_location = device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YwkIAVBHw5o"
      },
      "source": [
        "# model design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnyhEEkpPcyU"
      },
      "source": [
        "## regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t36uDJ9aoiJu"
      },
      "source": [
        "def train_loop_gpu_reg(n_epoches, optimizer, model, loss_fn, train_loader):\r\n",
        "  for epoch in range(1, 1+n_epoches):\r\n",
        "    train_loss = 0.0\r\n",
        "    for imgs, labels in train_loader:\r\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\r\n",
        "\r\n",
        "      outputs = model(imgs)\r\n",
        "      loss = loss_fn(outputs, imgs)\r\n",
        "\r\n",
        "      l2_lambda = 1e-3\r\n",
        "      l2_norm = sum(p.pow(2.0).sum() for p in model.parameters() )\r\n",
        "      loss += l2_norm\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      train_loss += float(loss)\r\n",
        "    if epoch == 1 or epoch%10==0:\r\n",
        "      print('{} Epoch {}, Loss {}'.format(datetime.datetime.now(), epoch, train_loss/len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAefA-aUPfRA"
      },
      "source": [
        "## dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YosgQ8Wjv8So"
      },
      "source": [
        "# dropout strategy, applying nn.dropout in out model\r\n",
        "import torch.nn as nn\r\n",
        "class NetDropOut(nn.Module):\r\n",
        "  def __init__(self, n_chansl = 32):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chansl = n_chansl\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chansl, 3, padding = 1)\r\n",
        "    self.drop1 = nn.Dropout2d(p=0.4)\r\n",
        "    self.conv2 = nn.Conv2d(n_chansl, n_chansl//2, 3, padding = 1)\r\n",
        "    self.drop2 = nn.Dropout2d(p=0.4)\r\n",
        "    self.fc1  = nn.Linear(8*8*n_chansl//2, 32)\r\n",
        "    self.fc2  = nn.Linear(32, 2)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv1(x) ), 2 )\r\n",
        "    out = self.drop1(out)\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv2(out)), 2 )\r\n",
        "    out = self.drop2(out)\r\n",
        "\r\n",
        "    out = out.view(-1, 8*8*self.n_chansl)\r\n",
        "\r\n",
        "    out = torch.tanh(self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_o38Q54Pko2"
      },
      "source": [
        "## batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghyTV4zc1YwL"
      },
      "source": [
        "# batch normalization, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d\r\n",
        "# 首先在__init__中要实现bn函数，其次在前向传播时，应在进入tanh之前运用bn\r\n",
        "class NetBN(nn.Module):\r\n",
        "  def __init__(self, n_chansl = 32):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chansl = n_chansl\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chansl, 3, padding = 1)\r\n",
        "    self.bn1 = nn.BatchNorm2d(n_chansl)\r\n",
        "    self.conv2 = nn.Conv2d(n_chansl, n_chansl//2, 3, padding = 1)\r\n",
        "    self.bn2 = nn.BatchNorm2d(n_chansl//2)\r\n",
        "    self.fc1  = nn.Linear(8*8*n_chansl//2, 32)\r\n",
        "    self.fc2  = nn.Linear(32, 2)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = self.bn1( self.conv1(x) )\r\n",
        "    out = F.max_pool2d(torch.tanh(out), 2)\r\n",
        "    out = self.bn2( self.conv2(out))\r\n",
        "    out = F.max_pool2d( torch.tanh(out), 2 )\r\n",
        "\r\n",
        "    out = out.view(-1, 8*8*self.n_chansl)\r\n",
        "\r\n",
        "    out = torch.tanh(self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm98WKNSPo4H"
      },
      "source": [
        "## res network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRmCjiew3gxV"
      },
      "source": [
        "# residual network, aidding to build a very deep model\r\n",
        "# change the activation function to nn.relu(), add another conv layer\r\n",
        "class NetDepth(nn.Module):\r\n",
        "  def __init__(self, n_chansl = 32):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chansl = n_chansl\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chansl, 3, padding = 1)\r\n",
        "    \r\n",
        "    self.conv2 = nn.Conv2d(n_chansl, n_chansl//2, 3, padding = 1)\r\n",
        "    self.conv3 = nn.Conv2d(n_chansl//2, n_chansl//2, 3, padding = 1)\r\n",
        "    self.fc1  = nn.Linear(4*4*n_chansl//2, 32)\r\n",
        "    self.fc2  = nn.Linear(32, 2)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.relu( self.conv1(x) ), 2 )\r\n",
        "    \r\n",
        "    out = F.max_pool2d( torch.relu( self.conv2(out)), 2 )\r\n",
        "    out = F.max_pool2d( torch.relu( self.conv3(out)), 2 )\r\n",
        "\r\n",
        "    out = out.view(-1, 4*4*self.n_chansl)\r\n",
        "\r\n",
        "    out = torch.relu(self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UavqKa8W6erd"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "class NetRes(nn.Module):\r\n",
        "  def __init__(self, n_chansl = 32):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chansl = n_chansl\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chansl, 3, padding = 1)\r\n",
        "    \r\n",
        "    self.conv2 = nn.Conv2d(n_chansl, n_chansl//2, 3, padding = 1)\r\n",
        "    self.conv3 = nn.Conv2d(n_chansl//2, n_chansl//2, 3, padding = 1)\r\n",
        "    self.fc1  = nn.Linear(4*4*n_chansl//2, 32)\r\n",
        "    self.fc2  = nn.Linear(32, 2)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.relu( self.conv1(x) ), 2 )\r\n",
        "    out = F.max_pool2d( torch.relu( self.conv2(out)), 2 )\r\n",
        "\r\n",
        "    out1 = out\r\n",
        "\r\n",
        "    out = F.max_pool2d( torch.relu( self.conv3(out)) + out1, 2 )\r\n",
        "    out = out.view(-1, 4*4*self.n_chansl)\r\n",
        "    out = torch.relu(self.fc1(out) )\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiE2dXwJPskA"
      },
      "source": [
        "## build a very deep NES network\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3enFgBHPY3M"
      },
      "source": [
        "# it consists of 100 ResBolocks and other parts\r\n",
        "# 1 write a subclass: ResBlock\r\n",
        "class ResBlock(nn.Module):\r\n",
        "  def __init__(self, n_chans):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chans = n_chans\r\n",
        "    self.conv = nn.Cov2d(n_chans, n_chans, 3, padding=1, bias=False)\r\n",
        "    self.bn  = nn.BatchNorm2d(num_features = n_chans)\r\n",
        "    \r\n",
        "    torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity = 'relu') #initialize bn's paras according to some paper\r\n",
        "\r\n",
        "    torch.nn.init.constant_(self.bn.weight, 0.5)\r\n",
        "\r\n",
        "    torch.nn.init.zeros_(self.bn.bias)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    out = self.conv(x)\r\n",
        "    out = self.bn(out)\r\n",
        "    out = torch.relu(out)\r\n",
        "    return out+x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bZKuJ_GVf9M"
      },
      "source": [
        "# 2 build the whole network\r\n",
        "class NetResDeep(nn.Module):\r\n",
        "  def __init__(self, n_chans1=32, n_blocks = 10):\r\n",
        "    super().__init__()\r\n",
        "    self.n_chans1 = n_chans1\r\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, 3, padding = 1)\r\n",
        "    self.resblocks = nn.Sequential(\r\n",
        "        *(n_blocks * [ResBlock(n_chans = n_chans1)])\r\n",
        "    )\r\n",
        "    self.fc1 = nn.Linear(8*8*n_chans1, 32)\r\n",
        "    self.fc2 = nn.Linear(32, 2)\r\n",
        "  \r\n",
        "  def forward(self, x):\r\n",
        "    out = F.max_pool2d( torch.tanh( self.conv1(x)), 2 )\r\n",
        "    out = self.resblocks(out)\r\n",
        "    out = F.max_pool2d(out, 2)\r\n",
        "    out = out.view(-1, 8*8*self.n_chans1)\r\n",
        "    out = torch.tanh(self.fc1(out))\r\n",
        "    out = self.fc2(out)\r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pZ3GvxjYKMB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}